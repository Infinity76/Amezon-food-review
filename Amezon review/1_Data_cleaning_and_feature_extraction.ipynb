{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/EnesGokceDS/Amazon_Reviews_NLP_Capstone_Project/blob/master/1_Data_cleaning_and_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mw4uZNMcgu1P"
   },
   "source": [
    "### **In this study, I will apply data cleaning and feature extraction methods on Amazon Reviews dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MtIB4ZeYg8Ry"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "FgkpYR4g6Bvg",
    "outputId": "f007c5cd-8815-49cf-e013-363688d3a5ca"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N3atGC5iSK7L"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "iuSRbmjVSLeF",
    "outputId": "218ad7b1-182e-4d98-e113-a4ef2a5d5928"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/rohitmeena/Desktop/Python/Reviews.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "id": "2GYBRwiySVwX",
    "outputId": "644ad6c4-89c5-4494-d4d8-482e63b29a11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "CWybHT2yS0qk",
    "outputId": "762f31c7-85d3-4989-af20-d0a887214064"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>568454.0</td>\n",
       "      <td>568454.0</td>\n",
       "      <td>568454.0</td>\n",
       "      <td>568454.0</td>\n",
       "      <td>5.684540e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>284227.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.296257e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>164098.7</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.804331e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.393408e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>142114.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.271290e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>284227.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.311120e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>426340.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.332720e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>568454.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.351210e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id  HelpfulnessNumerator  HelpfulnessDenominator     Score  \\\n",
       "count  568454.0              568454.0                568454.0  568454.0   \n",
       "mean   284227.5                   1.7                     2.2       4.2   \n",
       "std    164098.7                   7.6                     8.3       1.3   \n",
       "min         1.0                   0.0                     0.0       1.0   \n",
       "25%    142114.2                   0.0                     0.0       4.0   \n",
       "50%    284227.5                   0.0                     1.0       5.0   \n",
       "75%    426340.8                   2.0                     2.0       5.0   \n",
       "max    568454.0                 866.0                   923.0       5.0   \n",
       "\n",
       "               Time  \n",
       "count  5.684540e+05  \n",
       "mean   1.296257e+09  \n",
       "std    4.804331e+07  \n",
       "min    9.393408e+08  \n",
       "25%    1.271290e+09  \n",
       "50%    1.311120e+09  \n",
       "75%    1.332720e+09  \n",
       "max    1.351210e+09  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "VYpgB2tPS9uR",
    "outputId": "34b3b236-9af0-410a-babe-8b142d114b64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Summary</th>\n",
       "      <td>27</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProfileName</th>\n",
       "      <td>16</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProductId</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserId</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        null  percent\n",
       "Summary                   27    0.005\n",
       "ProfileName               16    0.003\n",
       "Id                         0    0.000\n",
       "ProductId                  0    0.000\n",
       "UserId                     0    0.000\n",
       "HelpfulnessNumerator       0    0.000\n",
       "HelpfulnessDenominator     0    0.000\n",
       "Score                      0    0.000\n",
       "Time                       0    0.000\n",
       "Text                       0    0.000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine how many missing values exist in the collection, in which case you can use .sum() chained onto is.na()\n",
    "null_values=df.isna().sum()\n",
    "null_values=pd.DataFrame(null_values,columns=['null'])\n",
    "sum_tot=len(df)\n",
    "null_values['percent']=null_values['null']/sum_tot*100\n",
    "round(null_values,3).sort_values('percent',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f9Pj6bFjZk_K"
   },
   "source": [
    "We have small number of missing values. We can drop them completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "wSlkx8rBY4q1",
    "outputId": "441cd552-63af-4d08-b4b1-bec55ebd1fbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568411, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uMQnlxMoZrCC"
   },
   "source": [
    "# Basic Feature Extraction - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3qzq7Z2XZt4v"
   },
   "source": [
    "Normally, I tried to make data cleaning first. Then, I realized that while making data cleaning, I am losing some of characters that can help data cleaning. Therefore, there will be two part of feature extraction. Here, I will extract features that can't be exracted after data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AyuO7pdDZznX"
   },
   "source": [
    "### 1) Number of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "id": "FXCED1U_ZzCD",
    "outputId": "e7232253-654f-4f50-c42d-69a98cb531aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rohitmeena/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rohitmeena/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rohitmeena/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rohitmeena/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "!pip install -q wordcloud\n",
    "import wordcloud\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "I-aTbPcnSUfP",
    "outputId": "206e5be3-dbdf-4b92-9532-ee63f9ffe271"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  stopwords\n",
       "0  I have bought several of the Vitality canned d...         21\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...         12\n",
       "2  This is a confection that has been around a fe...         42\n",
       "3  If you are looking for the secret ingredient i...         15\n",
       "4  Great taffy at a great price.  There was a wid...         12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stopwords'] = df['Text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "df[['Text','stopwords']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jOimT9DYhbUb"
   },
   "source": [
    "2. Number of Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRtk9lil9VCx"
   },
   "outputs": [],
   "source": [
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return count\n",
    "\n",
    "df['punctuation'] = df['Text'].apply(lambda x: count_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "Rwdr0fiRa6i1",
    "outputId": "2c042567-ccc7-4f19-d328-111b537463ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>punctuation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  punctuation\n",
       "0  I have bought several of the Vitality canned d...            3\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...            7\n",
       "2  This is a confection that has been around a fe...           18\n",
       "3  If you are looking for the secret ingredient i...            5\n",
       "4  Great taffy at a great price.  There was a wid...            5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Text','punctuation']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "se2IozmTaOQf"
   },
   "source": [
    "### 2) Number of hashtag characters\n",
    "\n",
    "One more interesting feature which we can extract from a review is calculating the number of hashtags or mentions present in it. This also helps in extracting extra information from our text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "heKqiw6c9VG0",
    "outputId": "97924133-d8ba-40d2-b391-403e2b9f8701"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>hastags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  hastags\n",
       "0  I have bought several of the Vitality canned d...        0\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...        0\n",
       "2  This is a confection that has been around a fe...        0\n",
       "3  If you are looking for the secret ingredient i...        0\n",
       "4  Great taffy at a great price.  There was a wid...        0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hastags'] = df['Text'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "df[['Text','hastags']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "q3MbnNH1bA5H",
    "outputId": "85f99f99-7a73-434c-df93-9b0284db2813"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1414"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.hastags.loc[df.hastags != 0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UQ67amRYamFu"
   },
   "source": [
    "### 3) Number of numerics\n",
    "Calculate the number of numerics which are present in the tweets can be useful. At least, it doesn't hurt to have such a data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "-Sy3VyUNamhv",
    "outputId": "314385f9-b20c-4fb3-dcee-139104635e6b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  numerics\n",
       "0  I have bought several of the Vitality canned d...         0\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...         0\n",
       "2  This is a confection that has been around a fe...         0\n",
       "3  If you are looking for the secret ingredient i...         0\n",
       "4  Great taffy at a great price.  There was a wid...         0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['numerics'] = df['Text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "df[['Text','numerics']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n0s4Y9KmaqvA"
   },
   "source": [
    "### 4) Number of Uppercase words\n",
    "Anger or rage is quite often expressed by writing in UPPERCASE words which makes this a necessary operation to identify those words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "AI4aA43ka2Vo",
    "outputId": "0902c309-2889-4769-80ce-6cf2fc9e3adc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  upper\n",
       "0  I have bought several of the Vitality canned d...      1\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      0\n",
       "2  This is a confection that has been around a fe...      2\n",
       "3  If you are looking for the secret ingredient i...      4\n",
       "4  Great taffy at a great price.  There was a wid...      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['upper'] = df['Text'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "df[['Text','upper']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BTJuoOSjcP7P"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dmLGGqN1a0_a"
   },
   "source": [
    "# **Text cleaning techniques**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PsQrL9pYcaCD"
   },
   "source": [
    "### Make all text lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rxgqwFY3ccu4"
   },
   "source": [
    "The first pre-processing step which we will do is transform our reviews into lower case. This avoids having multiple copies of the same words. For example, while calculating the word count, ‘Analytics’ and ‘analytics’ will be taken as different words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "ypjQgucycSqE",
    "outputId": "03ef3837-5236-4b32-91d1-046b73a5fc29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i have bought several of the vitality canned d...\n",
       "1    product arrived labeled as jumbo salted peanut...\n",
       "2    this is a confection that has been around a fe...\n",
       "3    if you are looking for the secret ingredient i...\n",
       "4    great taffy at a great price. there was a wide...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'] = df['Text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "df['Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oRuQsr1jcpyd"
   },
   "source": [
    "### Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "_XQbtgSpcYsw",
    "outputId": "b2ca0d8a-6134-4988-f476-dcf471896494"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k_/cl244mp92jz10s3tv63fkny00000gn/T/ipykernel_7328/3839621332.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Text'] = df['Text'].str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    i have bought several of the vitality canned d...\n",
       "1    product arrived labeled as jumbo salted peanut...\n",
       "2    this is a confection that has been around a fe...\n",
       "3    if you are looking for the secret ingredient i...\n",
       "4    great taffy at a great price there was a wide ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'] = df['Text'].str.replace('[^\\w\\s]','')\n",
    "df['Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cDNg_BGaenXo"
   },
   "source": [
    "### Removal of Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "id": "LpAwkZQMemjb",
    "outputId": "f06b746a-349e-4dbc-dd03-226157e637a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "563342    got free bar voxbox influenster wow soo yummy ...\n",
       "5689      product delicious say upfront thou semi messy ...\n",
       "479863    really like product use breads cook run rather...\n",
       "282706    cant find wheatena local shops buy great produ...\n",
       "111934    feel really given product fair chance cant get...\n",
       "469292    dog use get actually still get cronic ear infe...\n",
       "158912    taste good edible giving 1 star let people kno...\n",
       "183915    first stuff gives energy without cracked feeli...\n",
       "84601     tinkyada brand pasta wonderful holds like norm...\n",
       "403488    wonderful aroma plump moist beans great buy ni...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "df['Text'] = df['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df['Text'].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2MAvQ09NQ5As"
   },
   "source": [
    "### Removing URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kLJa1rgQQo8P"
   },
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DkJYkkCNQsyj"
   },
   "outputs": [],
   "source": [
    "# remove all urls from df\n",
    "import re\n",
    "import string\n",
    "\n",
    "df['Text'] = df['Text'].apply(lambda x: remove_url(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gnKhvH09ewO7"
   },
   "source": [
    "### Remove html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRcdtF6EQ-HU"
   },
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pqKhOD-YRCer"
   },
   "outputs": [],
   "source": [
    "# remove all html tags from df\n",
    "df['Text'] = df['Text'].apply(lambda x: remove_html(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dvQHrvdARMMK"
   },
   "source": [
    " ### Removing Emojis\n",
    "Emojis can be indictor of some emotions that can be related to being customer satisfaction. Unfortunately, we need to remove the emojis in our text analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r2YZxgFMRpDS"
   },
   "outputs": [],
   "source": [
    "# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "V-0FGg4-RthN",
    "outputId": "b7a505e1-e111-4dc0-c49b-17dadaef7b5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Omg another Earthquake '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example\n",
    "remove_emoji(\"Omg another Earthquake 😔😔\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0Qy59gKRxPY"
   },
   "outputs": [],
   "source": [
    "# remove all emojis from df\n",
    "df['Text'] = df['Text'].apply(lambda x: remove_emoji(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wVqAJNvIUF9I"
   },
   "source": [
    "###Remove Emoticons\n",
    "\n",
    "In previous steps, we have removed emoji. Now, going to remove emoticons. \n",
    "\n",
    "***What is the difference between emoji and emoticons?***\n",
    "\n",
    "*   :-) is an emoticon\n",
    "*   😜 → emoji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 93
    },
    "colab_type": "code",
    "id": "PUMYo_l3VplO",
    "outputId": "00aefcfb-532b-4d50-b998-7e34320f8685"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emot in /Users/rohitmeena/opt/anaconda3/lib/python3.9/site-packages (3.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install emot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OGXwq42UUKeh"
   },
   "outputs": [],
   "source": [
    "from emot.emo_unicode import EMOJI_UNICODE, EMOTICONS_EMO\n",
    "\n",
    "# Function for removing emoticons\n",
    "def remove_emoticons(text):\n",
    "    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in EMOTICONS_EMO) + u')')\n",
    "    return emoticon_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "GAQlHX3XUzH7",
    "outputId": "85513e16-8bf5-4de5-f198-e9cdf7252085"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "unbalanced parenthesis at position 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Example\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mremove_emoticons\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHello :-)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36mremove_emoticons\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_emoticons\u001b[39m(text):\n\u001b[0;32m----> 5\u001b[0m     emoticon_pattern \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m(\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m|\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mEMOTICONS_EMO\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m emoticon_pattern\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/re.py:252\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile\u001b[39m(pattern, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompile a regular expression pattern, returning a Pattern object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/re.py:304\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sre_compile\u001b[38;5;241m.\u001b[39misstring(pattern):\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst argument must be string or compiled pattern\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 304\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43msre_compile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (flags \u001b[38;5;241m&\u001b[39m DEBUG):\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_cache) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m _MAXCACHE:\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;66;03m# Drop the oldest item\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/sre_compile.py:764\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[1;32m    763\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[0;32m--> 764\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43msre_parse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    766\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/sre_parse.py:962\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munbalanced parenthesis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_DEBUG:\n\u001b[1;32m    965\u001b[0m     p\u001b[38;5;241m.\u001b[39mdump()\n",
      "\u001b[0;31merror\u001b[0m: unbalanced parenthesis at position 7"
     ]
    }
   ],
   "source": [
    "#Example\n",
    "remove_emoticons(\"Hello :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tHILrciOU_-O"
   },
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(lambda x: remove_emoticons(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hp-rANfLe5dr"
   },
   "source": [
    "### Spell Correction\n",
    "\n",
    "We’ve all seen tweets with a plethora of spelling mistakes. Our timelines are often filled with hastly sent tweets that are barely legible at times.\n",
    "\n",
    "In that regard, spelling correction is a useful pre-processing step because this also will help us in reducing multiple copies of words. For example, “Analytics” and “analytcs” will be treated as different words even if they are used in the same sense.\n",
    "\n",
    "To achieve this we will use the textblob library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "AFMenvnHe6er",
    "outputId": "1e79c968-287c-47c3-ba79-8dfb1b4bbff7"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "df['Text'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yYQJwam5fFgW"
   },
   "outputs": [],
   "source": [
    "# We could do some of the cleaning steps as a sum of opreation like this:\n",
    "\n",
    "# Apply a first round of text cleaning techniques\n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "mJGy_q3Af1fU",
    "outputId": "5af5956b-734e-46b2-ac05-e84e21f7fae6"
   },
   "outputs": [],
   "source": [
    "df['Text'] = df.Text.apply(round1)\n",
    "df.Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x9pQHdIhFAoX"
   },
   "outputs": [],
   "source": [
    "# Apply a second round of cleaning\n",
    "def clean_text_round2(text):\n",
    "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    return text\n",
    "\n",
    "round2 = lambda x: clean_text_round2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "f3DTSvZwFGaB",
    "outputId": "587729e0-6ee2-42a4-f44c-f47ca9ed5e34"
   },
   "outputs": [],
   "source": [
    "df['Text'] = df.Text.apply(round2)\n",
    "df.Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZLM2wykAFO6c"
   },
   "source": [
    "Let's check whether the frequent words make sense or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "colab_type": "code",
    "id": "n7NhgmICFK8M",
    "outputId": "765569d6-c92a-4c88-b057-e69ff99a133a"
   },
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(df['Text']).split()).value_counts()[:20]\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k_WoqQR9FXok"
   },
   "source": [
    "# Basic Feature Extraction - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aIXunJcIFbgg"
   },
   "source": [
    "###  Number of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "RbIMvtdNFXEb",
    "outputId": "ab6cea0f-45a4-4548-827a-583a2796893e"
   },
   "outputs": [],
   "source": [
    "df['word_count'] = df['Text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "df[['Text','word_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqwX7mM_FyKd"
   },
   "source": [
    "Again, let's check the data and number of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "colab_type": "code",
    "id": "qz_bkz3iFtQY",
    "outputId": "88d1abbc-4883-47ec-b4f4-2bad84a374a6"
   },
   "outputs": [],
   "source": [
    "null_values=df.isna().sum()\n",
    "null_values=pd.DataFrame(null_values,columns=['null'])\n",
    "sum_tot=len(df)\n",
    "null_values['percent']=null_values['null']/sum_tot*100\n",
    "round(null_values,3).sort_values('percent',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZlakthaIF7w0"
   },
   "source": [
    "### Number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "U6aAk1ZbF8GI",
    "outputId": "b1731dfb-f32e-48fb-aaa1-59f9dbc963f4"
   },
   "outputs": [],
   "source": [
    "df['char_count'] = df['Text'].str.len() ## this also includes spaces\n",
    "df[['Text','char_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3h8V9jEOGCpc"
   },
   "source": [
    "### 3) Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ygPPuLWqF_jh"
   },
   "outputs": [],
   "source": [
    "def avg_word(sentence):\n",
    "  words = sentence.split()\n",
    "  return (sum(len(word) for word in words)/(len(words)+0.000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "KV066OIPGG_M",
    "outputId": "701ef693-57fa-4283-d964-7f283498a30d"
   },
   "outputs": [],
   "source": [
    "df['avg_word'] = df['Text'].apply(lambda x: avg_word(x)).round(1)\n",
    "df[['Text','avg_word']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "tLtUDxmTGIBe",
    "outputId": "37971937-bcd6-48f5-919c-7efd7943e1cf"
   },
   "outputs": [],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KUiU-wlaMFMT"
   },
   "source": [
    "**Let's convert the 'time' column to a meaningful format**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-9FA4_JMEQf"
   },
   "outputs": [],
   "source": [
    "df['Time'] = pd.to_datetime(df['Time'],unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "colab_type": "code",
    "id": "6WuKgpjEMZFe",
    "outputId": "8561d6f8-0195-467c-dbd0-f403443ca6c5"
   },
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgsPZK9sGxf8"
   },
   "source": [
    "Lastly, we don't need 'ProfileName' feature because we already have 'UserId'. Therefore, we can drop 'ProfileName'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bN-LVDp1HFX6"
   },
   "outputs": [],
   "source": [
    "df= df.drop('ProfileName', axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "id": "Dj-dFcLnHhSS",
    "outputId": "0106ad41-2df1-493d-ad05-ae23140afcde"
   },
   "outputs": [],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "-fit5NF3KG0n",
    "outputId": "64e09f9c-1b24-4831-cc9a-8675dd3c771d"
   },
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sxN2Ifh_M2qM"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "##**Now, let's apply round 1 and round 2 data cleaning processes on 'Summary' column**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_QVdtbLrNR-f"
   },
   "source": [
    "Keep in mind that round1 operations make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "t_CdpuzhNGiP",
    "outputId": "ccbb84a0-979a-46f7-8804-140c330c8a27"
   },
   "outputs": [],
   "source": [
    "df['Summary'] = df.Summary.apply(round1)\n",
    "df.Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vtMJedmlNTtn"
   },
   "source": [
    "And, round2 operations get rid of some additional punctuation and non-sensical text that was missed the first time around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "hS6ks3u9NT26",
    "outputId": "92d0c9b0-b208-4353-924b-c4a8c518e233"
   },
   "outputs": [],
   "source": [
    "df['Summary'] = df.Summary.apply(round2)\n",
    "df.Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s16YIKS0qh7m"
   },
   "source": [
    "Let's check whether most frequent words make make. We can add our own stopwords depending on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 988
    },
    "colab_type": "code",
    "id": "hMEiy3cYqylo",
    "outputId": "ef860e74-e7de-4008-e2d8-b7040575e7bd"
   },
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(df['Text']).split()).value_counts()[:50]\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHMdbivzx2nu"
   },
   "source": [
    "#Adding own stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNiadYLxqhX2"
   },
   "outputs": [],
   "source": [
    "# Adding common words from our document to stop_words\n",
    "\n",
    "add_words = [\"br\",     \n",
    "\"also\",     \n",
    "\"im\",      \n",
    "\"ive\",      \n",
    "]\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stop_added = stop_words.union(add_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "colab_type": "code",
    "id": "THFDe1ctrqmt",
    "outputId": "4f45366a-6b96-4b5b-c13c-b4830f8c0646"
   },
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_added))\n",
    "df['Text'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YXIflGp5YbMw"
   },
   "outputs": [],
   "source": [
    "df1= df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXqsBVeGvJDV"
   },
   "outputs": [],
   "source": [
    "mask = df1.Text.str.endswith('br') \n",
    "df1.loc[mask, 'Text'] = df1.loc[mask, 'Text'].str[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y8AhhLGRkP4q"
   },
   "outputs": [],
   "source": [
    "df1['Text'] = df1['Text'].str.rstrip('tty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "zMevwHjdm8xx",
    "outputId": "b84b9884-bb4f-429e-a7d4-6264bf55504a"
   },
   "outputs": [],
   "source": [
    "df1['Text'].apply(lambda x: x[:-2] if x.endswith('tty') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "mS-2xaZCmN7j",
    "outputId": "7ffbe3e7-5ff6-476b-b976-ccb9215888f5"
   },
   "outputs": [],
   "source": [
    "df1.loc[df1.Text.str.endswith('br'), 'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "colab_type": "code",
    "id": "JlOI_uqLmsie",
    "outputId": "12f0b212-a1a3-4b5e-c882-3208809d20bd"
   },
   "outputs": [],
   "source": [
    "df1.loc[df1.punctuation >= 1000].Text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "colab_type": "code",
    "id": "7zSIpcicmd9-",
    "outputId": "c903a655-92a4-4246-cf56-d54e125f37b9"
   },
   "outputs": [],
   "source": [
    "df.loc[df.punctuation >= 1000].Text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 988
    },
    "colab_type": "code",
    "id": "7LjnxDCtxuQB",
    "outputId": "9cc0b834-9130-419a-ae35-47d8a2997da7"
   },
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(df['Text']).split()).value_counts()[:50]\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1IsIT-gjJHC-"
   },
   "source": [
    "**Now, let's save this clened processed data as CSV file** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W33GaarNHljs"
   },
   "outputs": [],
   "source": [
    "df.to_csv('Amazon_reviews_processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNkWM4Ow6asY7IKgXuDI4qA",
   "collapsed_sections": [
    "UQ67amRYamFu",
    "n0s4Y9KmaqvA",
    "PsQrL9pYcaCD",
    "oRuQsr1jcpyd",
    "dvQHrvdARMMK",
    "wVqAJNvIUF9I"
   ],
   "include_colab_link": true,
   "name": "1_Data_cleaning_and_feature_extraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
